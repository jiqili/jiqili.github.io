---
title: WebGL编程指导读书笔记
tags: [WebGL]
---

最近读完了《WebGL Programming Guide: Interactive 3D Graphics Programming with WebGL》。这本书比较系统地介绍了WebGL的各个方面，从基础的着色器语言，
到三维图形的绘制和变换，再到光照和纹理映射，最后还有一些高级技术，比如选中物体，HUD，雾化效果等。书中的例子也比较丰富，代码清晰易懂。
## 背景
三维图形渲染技术有微软的Direct3D和开源的OpenGL。Windows对OpenGL也是支持的。WebGL源于OpenGL。

其他渲染接口规范有Vulkan,苹果的Metal,还有WebGPU。其中Vulkan不像OpenGL那样大包大揽，许多都要程序员自己控制，并且Vulkan可以多线程处理，可以更快地把任务从CPU搬运到GPU.

WebGl会使用到颜色缓冲区和深度缓冲区，以及不常用的模板缓冲区。颜色缓冲区是下一帧要显示到浏览器画面上的像素。

WebGL清空canvas需要先用`clearColor`函数设置clear color然后再执行`clear`函数。
## 着色器
所有WebGL程序必须使用着色器(shader)的绘图机制。着色器分为顶点着色器和片元着色器。顶点着色器指定点的位置和尺寸，片元着色器指定点的颜色，负责纹理，光照计算等任务，相当于控制像素

着色器语言GLSL是强类型语言，整数类型的10赋值给float类型的变量会报错，必须是`10.0`。

`gl_Position`是`vec4`类型，里面有四个浮点数，前三个是xyz,第四个是类似于缩放的权重值。齐次坐标`(x, y, z, w)`等于`(x/w, y/w, z/w)`，这样能提高处理三维数据的效率，也可以使用矩阵乘法了。齐次坐标的w为1就可以当作三维坐标。

`gl.drawArrays(mode, first, count)`可以绘制很多图形，具体流程是从第一个点开始执行顶点着色器，这样点的位置和大小都被确定，直到点数等于count.比如画两个三角形，就是
```
gl.drawArrays(gl.TRIANGLES, 0, 3); // 第1个
gl.drawArrays(gl.TRIANGLES, 3, 3); // 第2个
```
### 存储限定符
`attribute`是存储限定符，后面跟类型和变量名，数据将从着色器外部传进该变量。传入之前需要调用`gl.getAttribLocation`获取其存储地址。该函数第一个参数是一个程序对象，第二个参数是变量名。然后使用`gl.vertexAttrib3f`把值传入该存储地址。此外，还有`gl.vertexAttrib1f`, `gl.vertexAttrib2f`, `gl.vertexAttrib4f`, `gl.vertexAttri1i`等。其中i代表整数。如果后缀是`4fv`,代表函数可以接受数组作为参数，这时候函数中的数字代表这个数组的元素个数。

存储限定符`uniform`后面也跟类型和变量名，查询变量地址的函数是`getUniformLocation`，赋值函数有`uniform4f`等。

`attribute`只用于顶点着色器，不用于片元着色器。片元着色器需要使用`uniform`或`varying`。并且在GLSL中只能指定float类型的attribute变量，而`uniform`变量不受限制。但是`uniform`定义的是只读常量，也就是在着色器代码里不能修改这个值，只能在下次绘制，也就是下次执行着色器代码前才能修改这个值。一般`uniform`用来存矩阵，纹理，灯光参数等。`attribute`用来存位置，颜色等。

`varying`限定符解决的是多种数据，比如位置和颜色数据写入同一缓冲区，但是只能给顶点着色器或者片元着色器，所以必然要提供一种顶点着色器和片元着色器之间传输数据的方式。这要求顶点着色器和片元着色器都要定义同名的varying变量，并且顶点着色器还要额外定义一个attribute变量接收缓冲区数据然后赋值给varying变量。varying变量只能是float类型。
### 精度限定词
精度限定词`precision`后面跟变量的范围和精度。

## WebGL坐标系
WebGL的原点是在canvas的中心，水平向右是x正方向，垂直向上是y正方向。我们需要把client坐标转到canvas坐标，然后再转到WebGL坐标。WebGL坐标是从-1到1.

WebGL遵守右手法则来定义的正旋转方向。

## 三角形的绘制与变换
三维模型的基本单位是三角形
### 缓冲区对象
一次性向着色器传入大量顶点的数据，减少JS->GPU往返，提升缓存和带宽利用。
- 第一步是`createBuffer`
- 第二步是`bindBuffer`把缓存区对象绑定到表示用途的目标，比如`ARRAY_BUFFER`。
- 第三步是`bufferData`向缓冲区写入数据，但是不能直接写入缓冲区，只能向目标写入数据，所以要先绑定缓冲区到目标。写入方式有：
    - 写一次用很多次的`gl.STATIC_DRAW`，如静态模型，天空盒
    - 写一次，绘制很少次，临时性的`gl.STREAM_DRAW`，如调试线框
    - 多次写，绘制多次的 `gl.DYNAMIC_DRAW`，如每帧的粒子系统
- 第四步是用`vertexAttribPointer`把整个缓冲区对象分配给attribute变量的存储位置。其中`stride`和`offset`有利于实现把多个缓冲区对象合进一个缓冲区对象中，比如一个具体步骤就是每个点前两个值代表坐标，最后一个点代表尺寸。
- 第五步是用`enableVertexArray(location)`激活缓冲区对象和attribute变量之间的连接。而且还可以关闭该连接。
- `drawArrays`函数总会执行着色器，如果执行了`enableVertexArray`了，那attribute就从缓冲区读数据，否则用常量。

### 类型化数组
不同于通用型的Array数组，`Float32Array`被称为类型化数组，这样处理起来更有效率。注意类型化数组没有`push`和`pop`方法，只有`get`和`set`方法，其中`set`可以是`set(index, value)`或从第offset个元素开始把array填充进去`set(array, offset)`。 还有new运算符。

### drawArrays
这个函数的第一个参数如果是`gl.POINTS`，那么就是绘制一些点，我们需要执行每个点的size。如果值是`gl.TRIANGLES`, 那就是画一个三个点围成的三角形。注意如果是带`STRIP`后缀的模式，那就是前后两点或者两边有共同的点或者边。注意，三个点的顺序很重要，因为这决定围成的面哪个是正面，哪个是反面，初始的三个点顺序决定哪面是正面。正面反面很重要，比如背面剔除会清除反面。一般默认顺时针的画的面是反面。

### 矩阵变换
3*3的矩阵可以用来表示旋转变换，但是平移因为有常量所以需要4*4的矩阵和[x, y, z, 1]相乘。又因为很多变换是平移和旋转合在一起的，所以我们要用4*4的矩阵表示旋转变换。4*4的矩阵我们在着色器语言中使用`mat4`类型，`mat4`*`vec4`在GLSL着色器语言中可以直接相乘，会得到一个`vec4`类型的结果。

值得一提的是，WebGL中矩阵是列主序的，和平时的写法不一样。

矩阵相乘，次序很重要，但是满足结合律，所以A*(B*C) = (A*B)*C，所以不必加括号。

### 光栅化
如果`drawArrays`的第一个值是`gl.POINTS`，那就是对点光栅化，如果是`gl.TRIANGLES`那就是对点围成的三角形光栅化，并且是根据坐标或者点的其他属性进行自动插值。自动插值可以帮助色彩平滑。三角形边缘是否光栅化取决于是否抗锯齿。

## 纹理
纹理映射就是把一张图片映射到几何图形表面。WebGL使用st来表示纹理的坐标，而非xy，左下角是原点。另一种方式是用uv表示纹理坐标。

- `Image`对象或者`<img />`一个DOM/JS对象，图片文件解码后把像素值存在浏览器内存里。我们要把浏览器内存的像素解包到GPU的存储中。注意，图片的坐标是左上角是原点。所以纹理映射的第一步就是使用`pixelStorei`函数进行Y轴翻转。
- WebGL通过一种叫做纹理单元的机制来同时使用多个纹理，例如`gl.TEXTURE0`, `gl.TEXTURE1`, ..., `gl.TEXTURE7`。使用纹理单元之前需要激活它。
- 然后绑定纹理对象到激活了的纹理单元，WebGL支持两种纹理类型，`gl.TEXTURE_2D`和`gl.TEXTURE_CUBE_MAP`。 后者是立方体纹理，是由6个2D纹理面组成的360度纹理，使得任意一个三维方向都能映射一个像素，常用于天空盒等。
- 然后配置纹理对象映射到图形上的参数（可选，有默认值），比如缩放和填充参数。有的映射方法渲染效果平滑，但是开销大，有的则相反。
- 把纹理图像传给纹理对象，`textImage2D`可以配置格式，数据类型，Image对象以及LOD要用到的level. LOD用到的纹理也称为金字塔纹理。
- 在片元着色器中，使用`uniform`变量表示纹理，因为纹理图像不会随着片元变化。`gl.TEXTURE2D`对应`sampler2D`类型的采样器。然后用`gl.uniform1i(sampler, 0)`把0号纹理单元传给采样器变量, 只有一个整数参数，所以是**li**
- GLSL内置的`texture2D(sampler, vec2)`函数可以根据坐标获取纹素

## GLSL ES
语法和C差不多，可以强转，基本的运算符都一样，三元运算符也是支持的。比较特别的是支持矢量和矩阵。

矢量的数据类型有
- 浮点数矢量： `vec2`，`vec3`，`vec4`
- 整数矢量： `ivec2`，`ivec3`, `ivec4`
- 布尔矢量： `bvec2`，`bvec3`，`bvec4` 

矩阵有`mat2`，`mat3`，`mat4`，不过这些都是浮点数元素的矩阵。

构造矢量的方式：
- `vec3 v3 = vec3(1.0, 1.0, 1.0);`
- `vec2 v2 = vec2(v3);` ---------------------- 使用v3的前两个元素
- `vec4 v4 = vec4(1.0);`
- `vec4 v4b = vec4(v2, v4);` ----------------- 把v2和v4的前两个元素组合

构造矩阵的方式：
```
mat4 m4 = mat4 ( 1.0,  2.0,  3.0,  4.0, 
                 5.0,  6.0,  7.0,  8.0,
                 9.0, 10.0, 11.0, 12.0,
                13.0, 14.0, 15.0, 16.0); // [1.0, 2.0, 3.0, 4.0]是第一列元素

vec2 v2_1 = vec2(1.0, 3.0);
vec2 v2_2 = vec2(2.0, 4.0);
mat2 m2_1 = mat2(v2_1, v2_2);

vec4 v4 = vec4(1.0, 2.0, 3.0, 4.0);
mat2 m2_2 = mat2(v4);               // 把v4的前两个元素作为第一个列向量

mat2 m2_3 = mat2(1.0, 3.0, v2_2);

mat2 m2_4 = mat2(1.0);              // 单位矩阵
```

访问矢量的元素可以使用`.`运算符，事实上任何矢量的x, r或s分量都会返回第一个分量。y, g或者t返回第二个矢量。而且还可以混合访问，比如
```
vec3 v3 = vec3(1.0, 2.0, 3.0);
vec2 v2 = v3.xy;

v2.xy = vec2(4.0, 5.0);
```
另一种访问方法是通过`[]`运算符，对于矩阵来说，`[0]`访问的是第一列元素，`[0][0]`和`[0].x`访问的都是第一列的第一个元素。

有个限制是`[]`中的索引值必须是常量索引值，比如整型字面量，const修饰的变量，**循环索引**，以及这三者组成的表示式。uniform变量也可以作为数组的索引。

比较矢量和矩阵的大小可以通过内置函数，例如`lessThan`

矢量/矩阵和浮点数加减乘除 = 每个分量都和浮点数加减乘除

矩阵右乘矢量 => 矢量；矩阵左乘矢量 => 矢量，但结果不一样

GLSL ES支持结构体和一维数组，例如`vec4 vec4Array[2];`声明了两个vec4对象的数组。数组的元素必须要显式地对每个元素进行初始化：
```
vec4Array[0] = vec4(4.0, 3.0, 2.0, 1.0);
vec4Array[1] = vec4(4.0, 3.0, 2.0, 1.0);
```

取样器是内置的一种变量类型，只能uniform变量，赋值时只能用`gl.uniform1i`函数把纹理单元编号赋值给取样器

条件和循环语句也是支持的，continue，break和discard也是可以用的。discard只能在片元着色器中使用，表示放弃当前片元直接处理下一个片元。

函数也是支持的，但是函数里不能调用自己，也就是不支持说递归。目的是便于编译器对函数进行内联展开。此外还可以为函数参数指定限定字来控制参数的行为，分为复制一份传进函数的`in`，传入变量的引用`out`等等。默认是`in`

存储限定字除了attribute, varying和uniform,还有const限定字。attribute只用于顶点着色器中，类型是float, 矢量或矩阵。顶点着色器中能容纳的attribute变量的最大数目和设备有关，至少是8个。uniform用于顶点着色器和片元着色器中，是只读的，但不能是数组或结构体，如果顶点着色器和片元着色器声明了同名的uniform变量，那它就会被二者共享。uniform变量肯定是要JS向其赋值的，代表各顶点和片元共用的数据。varying变量必须在顶点着色器和片元着色器都有出现同名同类型的，并且类型只能是float, 矢量和矩阵，片元着色器中的varying变量的值通常是对应的顶点着色器中的varying变量插值后的结果。

精度限定词有`highp`，`mediump`和`lowp`。使用方式是`mediump float size;`或者在着色器代码顶部使用`precision`来声明着色器的默认精度，例如`precision mediump float;` 数据类型都有默认精度，但是片元着色器中float没有默认精度，所以我们必须手动指定。

预处理指令也是支持的

## 三维空间
### 立方体
12个三角形组成一个立方体。可以调用`gl.drawArrays`画12个三角形或6个扇面。一种更好的办法是使用`gl.drawElements`在`gl.ELEMENT_ARRAY_BUFFER`缓冲区上写入顶点数据的索引。然后绘制时不再根据`gl.ARRAY_BUFFER`中的顶点顺序了，而是根据`gl.ELEMENT_ARRAY_BUFFER`中存的索引来到`gl.ARRAY_BUFFER`中找顶点数据。这样一来，不考虑颜色的情况下，我们只需要用6个点。

如果要为六个面都指定颜色，需要每个面都指定四个颜色值相同的点，那就是24个点。

### 视点和视线
视点就是观察者所在位置，从视点出发沿着观察方向的射线称作视线。

还需要上方向，这样才能确定屏幕上显示的图像，仅仅确定了视点和观察点的话，观察者还可能以视线为轴旋转的。所以上方向，视点和观察点构成了视图矩阵传给顶点着色器。图案的点的平移是可以用矩阵相乘实现的，点的旋转也是可以用矩阵相乘实现，所以图案的变换可以用矩阵相乘实现。从视线看中心点，相当于图案进行了变换，所以视图的图案也可以用矩阵相乘实现。如果是基于某个视角看某个旋转的物体，那就还要乘上物体本身的旋转矩阵。

### 可视范围
WebGL限制了水平和垂直的可视范围以及可视深度。这三者定义了可视空间。可视空间分为正射投影产生的盒状空间以及透视投影产生的金字塔可视空间。透视投影产生的三维场景更加自然，更有深度感，符合人眼观察效果。而正射投影好处在于可以方便地比较物体，因为物体看上去的大小和所在位置无关。

- 盒状空间

可视空间分为近裁剪面和远裁剪面，canvas上显示的是近裁剪面，如果宽高不一样就会进行压缩，可能会产生扭曲。把盒状空间的矩阵和点的坐标矢量相乘，如果结果`(x, y, z, w)`中任一分量不在 `[-1, 1]` 之间就不显示。定义参数是由两个三维点坐标构成

```
`l < x < r` <=> `-1 < (2x - (l + r))/(r - l) < 1` <=> `-1 < 2x / (r - l) - (l + r) / (r - l) < 1`
`b < y < t` <=> `-1 < (2y - (b + r))/(t - b) < 1` <=> `-1 < 2y / (t - b) - (t + b) / (t - b) < 1`
`f < z < n` <=> `-1 < (2z + (n + f))/(n - f) < 1` <=> `-1 < 2z / (n - f) + (f + n) / (n - f) < 1` or `-1 < -2z / (f - n) - (f + n) / (f - n) < 1`
```

这样就可以把左右变成-1和1这种常数了，这是从把xyz裁剪到[-1, 1]区间的角度来进行映射，另一种理解是先把中心点`[(l+r)/2, (b+t)/2, (f+n)/2]`平移到原点，然后在xyz方向上分别缩放到[-1, 1]。

- 透视投影

也有近裁剪面和远裁剪面，但是定义参数有四个参数构成，也就是近裁剪面和远裁剪面的位置，近裁剪面的宽高比`aspect`以及可视空间顶面和底面间的夹角`fov`。

和正射投影类似，但是因为近裁剪面和远裁剪面大小不一样，所以平移的系数里会包含z方向上的距离因子。变换过程是先把椎体压缩成长方体，这个过程保证z不变，x和y等比缩小。这个过程要保证两个原则：
1. 近平面的点的坐标`(x, y, n, 1)`矩阵变换后都不变
2. 远平面的中心点的坐标`(0, 0, f, 1)`矩阵变换后也不变
由此得出从透视投影矩阵到正射投影的变换矩阵

然后就是再乘正射投影矩阵。

以上推导都是建立在视点在原点，向上的方向为y轴的条件下。所以实际计算还需要考虑视图矩阵，模型本身的变换矩阵。合在一起叫做模型视图投影矩阵。

WebGL提供了隐藏面消除，可以消除z轴方向上，也就是深度上被消除的表面，这样我们就不必顾及因在缓冲区中顺序靠后而显示的问题。只需要`gl.enable(gl.DEPTH_TEST)`并且`gl.clear(gl.DEPTH_BUFFER_BIT)`。后面一个函数是为了清除深度缓冲区，深度缓冲区就是用来隐藏面消除的，在顶点着色器执行后是片元着色器，然后是深度检测，最后是处理颜色缓冲区和深度缓冲区。

同时清除颜色缓冲区和深度缓冲区可以使用按位或操作符: `gl.clear(gl.COLOR_BUFFER_BIT | gl.DEPTH_BUFFER_BIT)`

深度冲突：如果两个表面过于接近，深度缓冲区有限的精度不能区分哪个在前，哪个在后了。WebGL提供了**多边形偏移**技术来自动在Z值加一个偏移量，偏移量的值由物体表面相对于观察者视线决定

## 光照
分为平行光，点光源和环境光。

### 漫反射光和环境反射光
物体表面反射光线的方式有两种：
- 漫反射光的颜色 = 入射光 * 表面基底色 *（入射光和表面的法线夹角的余弦值）= 入射光 * 表面基底色 *（光线方向·法线方向）
- 环境反射 = 入射光 * 表面基底色
表面的反射光颜色= 漫反射光颜色 + 环境反射光颜色

矢量点积的直观解释：b矢量在a矢量方向上的投影长度和a矢量长度的乘积

计算漫反射光线时需要让光线矢量和法线矢量的长度为1，否则反射光的颜色会过亮或者过暗。

运动中的物体，平移变换不会改变法向量，但是旋转变换会改变法向量。旋转变换后的法向量求解需要用到**逆转置矩阵**

法向量*模型矩阵的逆转置矩阵 => 变换后的法向量（原理是法向量始终和表面的切向量垂直）

求逆转置矩阵需要先求逆矩阵再转置，逆矩阵的含义是矩阵和自身的逆矩阵相乘会得到单位矩阵，有点像倒数。

### 点光源
顶点在世界坐标系中的坐标和点光源的坐标可以得到点光源在顶点处的方向矢量，然后归一化保证该矢量长度为1.0,然后计算光线方向矢量和法向量的点积，从而算出顶点的颜色。

还需要考虑片元的插值，我们需要逐片元地计算点光源的光照，这个过程在片元着色器中计算。片元着色器中的坐标和法向量是顶点着色器以varying变量的形式传入的，片元着色器中的同名变量就已经是内插后的值了。

## 层次模型
例如机械臂，按照模型中的各个部件的层次顺序，从高到低逐一绘制，在每个关节上应用模型矩阵，所以一个关节可能会应用了多个模型矩阵，会有多个矩阵相乘。

如果一个部件有兄弟部件，比如手掌上的五根手指，可以将模型矩阵压入栈中，绘制完弹出即可。
## 高级技术
### 选中物体
原理是把物体重绘成某个特定颜色，然后调用`gl.readPixels()`从颜色缓冲区获取鼠标点击处的颜色是否是该颜色，然后恢复物体颜色。如果是多个物体只需要为场景里的每个物体指定不同颜色即可。

如果是选中面，就把面的下标写到颜色矢量的第四个元素中。
### HUD
原理是把两个canvas位置重叠，浏览器会自动将二者混合
### 雾化（大气效果）
在片元着色器中计算片元颜色时考虑距离来完成雾化效果。

还可以使用顶点经过模型视图投影矩阵变换后的坐标的w分量来近似表示顶点到视点的距离。
### 画圆
`gl_PointCoord`表示当前片元的坐标，坐标值的区间从0.0到1.0，这样只需要比较到中心点`(0.5, 0.5)`的距离是否大于0.5来决定是否绘制片元的颜色。
### 透明度混合
WebGL可以开启透明度混合: `gl.enable(gl.BLEND)`，混合函数也是要设置的。

#### 透明和不透明物体共存
- 开启隐藏面消除功能
- 绘制所有不透明的物体
- 锁定用于隐藏面消除的深度缓冲区的写入操作，使之只读
- 绘制所有半透明的物体，按照深度顺序从后往前绘制
- 释放深度缓冲区，使之可读写

这样做的原因有几点：首先隐藏面消除肯定是要开的，否则片元不再比较深度，绘制顺序决定了遮挡关系。然后不透明物体都正确绘制好了后，被不透明物体遮挡的半透明物体因为隐藏面消除功能开启了所以被正确遮挡了。半透明物体遮挡的不透明物体因为深度缓冲区的写入被锁，所以深度缓冲区不会更新，所以半透明和不透明物体都被画出来，然后经过透明度混合后也被正确渲染了。
### 切换着色器
先使用`createProgram`创建着色器对象，然后`gl.useProgram`函数可以指定使用哪个着色器对象，然后通过缓冲区对象向着色器中传入变量值，并开启之，这样就绘制了三维模型。由此我们可以在场景中绘制各种各样的三维模型。
### 渲染到纹理（Render To Texture, RTT）
WebGL绘制的结果图像是存在颜色缓冲区的，帧缓冲区对象可以用来代替颜色缓冲区或深度缓冲区，我们可以对帧缓冲区中的内容进行处理或者直接读取其内容作为纹理图像。在帧缓冲区中进行绘制的过程又称为离屏绘制。

帧缓冲区有三个关联对象：颜色关联对象，深度关联对象和模板关联对象。每个关联对象又分为渲染缓冲区对象和纹理对象。

RTT的原理是把片元着色器的输出目标写入自己创建的帧缓冲区对象引用的纹理显存，片元着色器的输出就已经是一个2D图像了，所以这也就是一个纹理图片。
### 绘制阴影
原理是预先在光源视角捕获“哪些位置被光看到”，这些位置都是光看到的最近表面。比如对于遮挡物在地面上的阴影，这些位置可能是遮挡物也可能是地面，这些位置要存起来。这是一个map,可以得到光源视角下，阴影贴图上xy对z的映射。然后在相机视角下的顶点着色器中计算空间点在屏幕上的投影坐标以及在阴影贴图上的坐标，然后把阴影贴图上的坐标通过varying变量传到片元着色器中，而屏幕坐标会被片元着色器自动使用。

`gl.FragCoord`是vec4类型的，x和y是在屏幕上的坐标，z是深度值。这个值会被归一化，如果z是0表示在近裁表面，如果是1表示在远裁表面。片元的坐标是经过点的坐标插值后得来的，然后还要做从（-1,1）到（0,1）的变换。

#### 马赫带
纹理图像的RGBA分量是8位的，而坐标的分量是16位的。精度不同，造成了最小单位的不同，所以判断大小的时候会出错，某些区域会被误认为是阴影。

#### 提高精度
纹理图像的RGBA分量是8位的，所以范围是0～255。当数值过大时会有问题。如果用RGBA四个分量表示一个数值，就可以得到32位的数值。

提高精度的过程和原理是把数值d展开为`d = B0 + B1/256 + B2/(256*256) + B3/(256*256*256) + ...`其中Bk是0～255的整数。
```
B0 = floor(d) - floor(d*256)/256
B1 = floor(d*256) - floor(d*256*256)/256
B2 = floor(d*256*256) - floor(d*256*256*256)/256
B3 = floor(d*256*256*256) - floor(d*256*256*256)*0

可以提出来的数据有[floor(d), floor(d*256), floor(d*256*256), floor(d*256*256*256)]
```
### 三维模型
OBJ是基于文本的，易于理解和转换，OBJ格式也存在不同的变体。

OBJ中定义了顶点，使用的材质名称以及每个面的顶点组成。

材质中定义了各种光的颜色。
### 响应上下文丢失
计算机的图形硬件是被操作系统管理的，由包括浏览器的多个应用共享。在某些情况下，如果另一个应用接管了图形硬件，或者系统进入休眠，浏览器就会失去使用这些资源的全力，导致数据丢失，那么WebGL绘图上下文就会丢失。

但是丢失的只是GPU里的资源，JavaScript变量都还在的，所以能够恢复。恢复的过程就是重新执行着色器渲染等。